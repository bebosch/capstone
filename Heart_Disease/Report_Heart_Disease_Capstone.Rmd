---
title: "Report on Hearth Disease Project"
author: "Benedikt Bosch"
date: "8th August 2020"
output: pdf_document
---

```{r setup, include=FALSE, warning = FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align = 'center')
```
  
# Overview over the Heart Disease project

For this capstone project within Harvard's Professional Certificate in Data Science, I created a heart disease prediction model using the Heart Disease dataset and all the tools shown throughout the courses in this certificate. Within this project, I trained a machine learning algorithm using a training subset of the Heart Disease dataset in order to predict the prevalence of heart disease in the complementary testing set. Doing so, my model was able to yield an **accuracy** of **0.92** by using a **logistic regression model**.

# Heart Disease dataset

The original Heart Disease dataset was generated by the Hungarian Institute of Cardiology, the University Hospital Zurich, the University Hospital Basel, the V.A. Medical Center Long Beach and the Cleveland Clinic Foundation. It includes the diagnosis data of heart disease (angiographic disease status) for 303 patients, splitted into 13 different variables. This dataset will be referred to in the following as Heart Disease datset. It can be found under the following link: https://archive.ics.uci.edu/ml/datasets/Heart+Disease

# Approach and analysis overview

I developed my algorithm using the test set (80% of the data of the Heart Disease dataset). To test the algorithm, I predicted the prevalence of heart disease in the test set (20% of the data of the Heart Disease dataset) as if it was unknown. To evaluate how close my predictions were to the true values in the test set, accuracy (% of correct predictions) was used as loss function.

```{r accuracy, echo = FALSE, message = FALSE}
accuracy <- function(predicted_num, true_num){
  confusionMatrix(predicted_num, true_num)$overall[["Accuracy"]]
}
```

# Data cleaning

```{r libraries, echo = FALSE, message = FALSE}
# install all required libraries (note: this process could take a couple of minutes)
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(lubridate)) install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(randomForest)) install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(knitr)) install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(rpart)) install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(rpart.plot)) install.packages("data.table", repos = "http://cran.us.r-project.org")

# load all required libraries
library(tidyverse)
library(caret)
library(data.table)
library(lubridate)
library(randomForest)
library(knitr)
library(rpart)
library(rpart.plot)

# set digit places to 5
options(digits = 5)
```

```{r download_data, echo = FALSE, message = FALSE}
# download metadata
heart <- read.csv("https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data",header=FALSE,sep=",",na.strings = '?')

# add column names
names(heart) <- c("age", "sex", "chest_pain", "blood_pressure", "cholestoral","blood_sugar", "electrocardiography", "max_heart_rate", "exercise_angina", "ST_depression", "slope_peak", "major_vessels", "defect", "disease")
```

In a first step, after downloading the raw data, I inspected the head of the disease raw data.

```{r heart_rename, echo = FALSE, message = FALSE}
heart_renamed <- heart %>%
  rename(cp = chest_pain, bp = blood_pressure, chol = cholestoral, bs = blood_sugar, electro = electrocardiography, max_hr = max_heart_rate, ang = exercise_angina, STd = ST_depression, sp = slope_peak, ves = major_vessels, def = defect, dis = disease)
```


```{r disease_head, results = 'asis'}
kable(heart_renamed[1:6, ])
```

\newpage

The excerpt of the raw data revealed that the following 13 variables were available to train the machine learning algorithm in predicting whether heart disease was present or absent.

1.  Sex
2.  Age
3.  Chest pain type
4.  Resting blood pressure
5.  Serum cholestoral in mg/dl
6.  Fasting blood sugar > 120 mg/dl
7.  Resting electrocardiographic results
8.  Maximum heart rate
9.  Exercise induced angina
10. ST depression induced by exercise relative to rest
11. Slope of the peak exercise ST segment
12. Number of major vessels
13. Defect type

The last column "$disease$" indicates the angiographic disease status, differentiated by severeness from 0 to 4. For the purpose of this capstone project, I only attempted to distinguish between presence (values 1,2,3,4) and absence (value 0) of a heart disease.

```{r disease_simple, message = FALSE}
heart <- heart %>% 
  mutate(disease = ifelse(disease > 0, 1, 0))
```

In a next step, I tried to Identify whether the data is tidy or not. For this purpose, I had a look whether there any $nas$ in the data.

```{r na_identify, echo = FALSE, message = FALSE}
na_sum = sum(is.na(heart))
```

In total, there were `r na_sum` rows of patient data with na values, so I omitted these rows.

```{r na_omit, message = FALSE}
heart <- heart %>% 
  na.omit()
```

Before exploring the data in more detail, the data classes of the columns needed to be adjusted. When downloading the data, all colums were imported as numeric variables. However, a closer look revealed that the sex, chest_pain, blood_sugar, electrocardiography, exercise_angina, slope_peak, major_vessels, defect and disease columns are in fact factors. Consequently, those values are discrete variables whereas the other ones are continous ones.

```{r convert_factor, echo = FALSE, message = FALSE}
heart <- heart %>% 
  mutate(sex = as.factor(sex)) %>%
  mutate(chest_pain = as.factor(chest_pain)) %>%
  mutate(blood_sugar = as.factor(blood_sugar)) %>%
  mutate(electrocardiography = as.factor(electrocardiography)) %>%
  mutate(exercise_angina = as.factor(exercise_angina)) %>%
  mutate(slope_peak = as.factor(slope_peak)) %>%
  mutate(major_vessels = as.factor(major_vessels)) %>%
  mutate(defect = as.factor(defect)) %>%
  mutate(disease = as.factor(disease))
```

After tidying the data (297 observations Ã  13 variables remaining), the Heart disease dataset looks as following:

```{r heart_rename_2, echo = FALSE, message = FALSE}
heart_renamed <- heart %>%
  rename(cp = chest_pain, bp = blood_pressure, chol = cholestoral, bs = blood_sugar, electro = electrocardiography, max_hr = max_heart_rate, ang = exercise_angina, STd = ST_depression, sp = slope_peak, ves = major_vessels, def = defect, dis = disease)
```

```{r disease_head_clean, results = 'asis'}
kable(heart_renamed[1:6, ])
```

\newpage

# Insights gained through data exploration and visualization

For the data exploration part of this project, I had a look at the distribution of each variable in regard to the patient's disease presence in the Heart Disease dataset. First, I had a look at the continous variables by displaying their density distribution.

## Continous variables' distribution

` `

```{r age, echo = FALSE}
heart %>% 
  ggplot(aes(x = age, fill = disease, color = disease)) +
  geom_density(alpha = 0.2) +
  theme(legend.position = "bottom") +
  scale_x_continuous(name = "Age") +
  scale_fill_discrete(name = "Heart disease", labels = c("No", "Yes")) +
  scale_color_discrete(name = "Heart disease", labels = c("No", "Yes"))
```

```{r blood_pressure, echo = FALSE}
heart %>% 
  ggplot(aes(x = blood_pressure, fill = disease, color = disease)) +
  geom_density(alpha = 0.2) +
  theme(legend.position = "bottom") +
  scale_x_continuous(name = "Resting blood pressure") +
  scale_fill_discrete(name = "Heart disease", labels = c("No", "Yes")) +
  scale_color_discrete(name = "Heart disease", labels = c("No", "Yes"))
```

```{r cholestoral, echo = FALSE}
heart %>% 
  ggplot(aes(x = cholestoral, fill = disease, color = disease)) +
  geom_density(alpha = 0.2) +
  theme(legend.position = "bottom") +
  scale_x_continuous(name = "Serum cholestoral in mg/dl") +
  scale_fill_discrete(name = "Heart disease", labels = c("No", "Yes")) +
  scale_color_discrete(name = "Heart disease", labels = c("No", "Yes"))
```

```{r max_heart_rate, echo = FALSE}
heart %>% 
  ggplot(aes(x = max_heart_rate, fill = disease, color = disease)) +
  geom_density(alpha = 0.2) +
  theme(legend.position = "bottom") +
  scale_x_continuous(name = "Maximum heart rate") +
  scale_fill_discrete(name = "Heart disease", labels = c("No", "Yes")) +
  scale_color_discrete(name = "Heart disease", labels = c("No", "Yes"))
```

```{r ST_depression, echo = FALSE}
heart %>% 
  ggplot(aes(x = ST_depression, fill = disease, color = disease)) +
  geom_density(alpha = 0.2) +
  theme(legend.position = "bottom") +
  scale_x_continuous(name = "ST depression induced by exercise relative to rest") +
  scale_fill_discrete(name = "Heart disease", labels = c("No", "Yes")) +
  scale_color_discrete(name = "Heart disease", labels = c("No", "Yes"))
```

\newpage

Looking at the five graphs, it was discernible that only the maximum heart rate has significant predictive power to differentiate between presence and absence of a heart disease.

## Discrete variables' distribution

` `

Second, I had a look at the discrete variables by plotting their distribution in a bar chart.

` `

```{r sex, echo = FALSE}
heart %>%
  group_by(disease) %>% 
  count(sex) %>% 
  as.data.frame() %>%
  ggplot(aes(x = sex, y = n, fill = disease)) + 
  geom_bar(stat = "identity", position = "fill") +
  scale_x_discrete(name = "Sex", labels = c("Female", "Male")) +
  scale_fill_discrete(name = "Heart Disease", labels = c("No", "Yes")) +
  scale_color_discrete(name = "Heart Disease", labels = c("No", "Yes")) +
  theme(legend.position = "bottom")
```

```{r chest_pain, echo = FALSE}
heart %>%
  group_by(disease) %>% 
  count(chest_pain) %>% 
  as.data.frame() %>%
  ggplot(aes(x = chest_pain, y = n, fill = disease)) + 
  geom_bar(stat = "identity", position = "fill") +
  scale_x_discrete(name = "Chest pain type", labels = c("Typical angina", "Atypical angina", "Non-anginal pain", "Asymptomatic")) +
  scale_fill_discrete(name = "Heart Disease", labels = c("No", "Yes")) +
  scale_color_discrete(name = "Heart Disease", labels = c("No", "Yes")) +
  theme(legend.position = "bottom")
```

```{r blood_sugar, echo = FALSE}
heart %>%
  group_by(disease) %>% 
  count(blood_sugar) %>% 
  as.data.frame() %>%
  ggplot(aes(x = blood_sugar, y = n, fill = disease)) + 
  geom_bar(stat = "identity", position = "fill") +
  scale_x_discrete(name = "Fasting blood sugar > 120 mg/dl", labels = c("False", "True")) +
  scale_fill_discrete(name = "Heart Disease", labels = c("No", "Yes")) +
  scale_color_discrete(name = "Heart Disease", labels = c("No", "Yes")) +
  theme(legend.position = "bottom")
```

```{r electrocardiography, echo = FALSE}
heart %>%
  group_by(disease) %>% 
  count(electrocardiography) %>% 
  as.data.frame() %>%
  ggplot(aes(x = electrocardiography, y = n, fill = disease)) + 
  geom_bar(stat = "identity", position = "fill") +
  scale_x_discrete(name = "Resting electrocardiographic results", labels = c("Normal", "ST-T wave abnormality", "Left ventricular hypertrophy")) +
  scale_fill_discrete(name = "Heart Disease", labels = c("No", "Yes")) +
  scale_color_discrete(name = "Heart Disease", labels = c("No", "Yes")) +
  theme(legend.position = "bottom")
```

```{r exercise_angina, echo = FALSE}
heart %>%
  group_by(disease) %>% 
  count(exercise_angina) %>% 
  as.data.frame() %>%
  ggplot(aes(x = exercise_angina, y = n, fill = disease)) + 
  geom_bar(stat = "identity", position = "fill") +
  scale_x_discrete(name = "Exercise induced angina", labels = c("No", "Yes")) +
  scale_fill_discrete(name = "Heart Disease", labels = c("No", "Yes")) +
  scale_color_discrete(name = "Heart Disease", labels = c("No", "Yes")) +
  theme(legend.position = "bottom")
```

```{r slope_peak, echo = FALSE}
heart %>%
  group_by(disease) %>% 
  count(slope_peak) %>% 
  as.data.frame() %>%
  ggplot(aes(x = slope_peak, y = n, fill = disease)) + 
  geom_bar(stat = "identity", position = "fill") +
  scale_x_discrete(name = "ST depression induced by exercise relative to rest", labels = c("Upsloping", "Flat", "Downsloping ")) +
  scale_fill_discrete(name = "Heart Disease", labels = c("No", "Yes")) +
  scale_color_discrete(name = "Heart Disease", labels = c("No", "Yes")) +
  theme(legend.position = "bottom")
```

```{r major_vessels, echo = FALSE}
heart %>%
  group_by(disease) %>% 
  count(major_vessels) %>% 
  as.data.frame() %>%
  ggplot(aes(x = major_vessels, y = n, fill = disease)) + 
  geom_bar(stat = "identity", position = "fill") +
  scale_x_discrete(name = "Number of major vessels", labels = c("0", "1", "2", "3")) +
  scale_fill_discrete(name = "Heart Disease", labels = c("No", "Yes")) +
  scale_color_discrete(name = "Heart Disease", labels = c("No", "Yes")) +
  theme(legend.position = "bottom")
```

```{r defect, echo = FALSE}
heart %>%
  group_by(disease) %>% 
  count(defect) %>% 
  as.data.frame() %>%
  ggplot(aes(x = defect, y = n, fill = disease)) + 
  geom_bar(stat = "identity", position = "fill") +
  scale_x_discrete(name = "Defect type", labels = c("Normal", "Fixed defect", "Reversable defect ")) +
  scale_fill_discrete(name = "Heart Disease", labels = c("No", "Yes")) +
  scale_color_discrete(name = "Heart Disease", labels = c("No", "Yes")) +
  theme(legend.position = "bottom")
```

Looking at the eight graphs, it was discernible that the sex, the chest pain type, the exercise induced angina, the slope of the peak exercise ST segment, the number of major vessels and the defect type - but not the fasting blood sugar level or the resting electrocardiographic results - have significant predictive power to differentiate between presence and absence of a heart disease.

As a consequence of the data exploration, I decided to only keep variable columns that have significant predictive power to differentiate between presence and absence of a heart disease. These are the following seven variables:

1. Sex
2. Chest pain type
3. Maximum heart rate
4. Exercise induced angina
5. Slope of the peak exercise ST segment
6. Number of major vessels
7. Defect type

For all seven factors, biases could be clearly demonstrated: men are more likely to suffer from heart disease, asymptomatic chest pain is a likely indicator of a heart disease, persons with a maximum heart rate of more than 180 beats per minute rarely need to fear a heart disease, exercise induced angina significantly increases the risk of a heart disease, an upsloping peak exercise ST segment, zero major vessels and a normal defect type reduce disease risk. Consequently, an appropriate machine learning algorithm needs to take into account those factors.

\newpage

# Creation of train and validation sets

Before training the machine learning algorithm, a train and test set needed to be created from the Heart Disease data. The test set contained 20% of the Heart Disease data and was only used to to assess how close my predictions with different models were to the true values. The train set comprised 80% of the data and was used to train the different algorithms.

```{r train_and_test_set, echo = FALSE, message = FALSE, warning = FALSE}
set.seed(20, sample.kind="Rounding")
test_index <- createDataPartition(heart$disease, times = 1, p = 0.2, list = FALSE)
train_set <- heart[-test_index,]
test_set <- heart[test_index,]
```

After cleaning the data and creating the train and test set, the two datsets comprised the follwing number of ratings:

```{r overview_datasets, echo = FALSE}
overview_datasets <- tibble(Dataset = c("Train set", "Test set"), 
           Ratings = c(nrow(train_set), nrow(test_set)))
kable(overview_datasets)
```

# Modeling approach

A simple linear regression is normally a useful baseline approach but is often insufficiently flexible for more complex analyses. This is the case here. Therefore, to model the heart disease prediction system, I decided to use four different machine learning algorithms.

1. Logistic regression model
2. K-nearest neighbor model
3. Regression tree model
4. Random forest model

All four models are discriminative approaches that estimate the conditional probability directly and do not consider the distribution of the predictors. Generative models, to the contrary, can be very powerful when we the joint distribution of predictors conditioned on each class can successfully be estimated, which is not the case here. LDA (linear discriminant analysis) and QDA (quadratic discriminant analysis), for example, are not meant to be used with datasets that have many predictors as the number of parameters that need to be estimates becomes too large. Once the number of parameters approaches the size of the original data, the methods become impractical due to overfitting.

Each model was trained using the train set. After training the model, the presence of heart disease per patinet in the test set was predicted and the resulting accurcy calculated. Comparing the resulting accuracies, it was apparent that the logistic regression model is the best machine learning algorithm for this purpose.

## Logistic regression model

The baseline of the algorithm is the logistic regression model. It is the simplest possible recommendation system for the purpose of predicting categorical data: presence or absence of heart disease. Logistic regression is an extension of linear regression that assures that the estimate of conditional probability is between 0 and 1. This approach makes use of the logistic transformation by transforming probabilities to log odds. The odds tell you how much more likely something will happen compared to not happen.

` `

\begin{center}
$g(p) = log \displaystyle \frac{p}{1-p}$
\end{center}

\newpage

```{r glm_model, message = FALSE, warning = FALSE}
# compute fit of logistic regression algorithm
set.seed(20, sample.kind="Rounding")
glm_fit <- train(disease ~ ., data = train_set, method = "glm", family = "binomial")

# calculate predicted presence of heart disease (with glm)
glm_predicted_num <- predict(glm_fit, test_set)

# use logistic regression prediction to compute accuracy on the test set
glm_accuracy <- accuracy(glm_predicted_num, test_set$disease)
```

```{r glm_table, echo = FALSE, message = FALSE}
accuracy_results <- data_frame(method = "Logistic Regression", accuracy = glm_accuracy)
```

Logistic regression forces our predictions to be on a plane and our boundary to be a line. This implies that a logistic regression model has no chance of capturing a non-linear nature. For this reason, logistic regression is often limited and not flexible enough to be useful. However, the logistic regression model yields an accuracy of `r glm_accuracy`, the highest one of the four models.

## K-nearest neighbor model

K-nearest neighbors (kNN) estimates the conditional probabilities in a similar way to bin smoothing. However, kNN is easier to adapt to multiple dimensions. The general idea of smoothing is to group data points into strata in which the predicted value, here the disease status, can be assumed to be constant. This assumption can be made because the predicted value changes slowly and, as a result, is almost constant in small windows of time.

This assumption implies that a good estimate for the predicted value, $\hat{y}$ is the average of the predicted values, $Y_{i}$ in the window. This estimate can be expressed mathematically as follows:

` `

\begin{center}
$\hat{y} = \displaystyle \frac{1}{N_{0}}{\sum_{i\in A_{0}}^{}Y_{i}}$
\end{center}

` `

In smoothing, we call the size of the interval satisfying the particular condition the neighborhood.

```{r knn_model, message = FALSE, warning = FALSE}
# compute fit of knn algorithm
set.seed(20, sample.kind="Rounding")
knn_fit <- train(disease ~ ., data = train_set, method = "knn", 
                 tuneGrid = data.frame(k = seq(1, 151, 2)))

# calculate predicted presence of heart disease (with knn)
knn_predicted_num <- predict(knn_fit, test_set)

# use knn prediction to compute accuracy on the test set
knn_accuracy <- accuracy(knn_predicted_num, test_set$disease)
```

```{r knn_table, echo = FALSE, message = FALSE}
accuracy_results <- bind_rows(accuracy_results, data_frame(method = "K-Nearest Neighbor", 
                                                           accuracy = knn_accuracy))
```

```{r plot_knn, echo = FALSE}
# plot knn
ggplot(knn_fit, highlight = TRUE)

# calculate optimal k
k <- knn_fit$bestTune
half_k = (k - 1)  / 2
```

From the graph it is discernible that the value of k that optimizes the model is `r k`, so that the interval to the left and to the right includes the `r half_k` nearest neighbors on each side.

With kernel methods such as k-nearest neighbor, the optimal neighborhood to include a given percentage of the data becomes too large when multiple predictors are used, such as in this analysis. With larger neighborhoods, the method loses flexibility. That is why the k-nearest-neigbor model performs significantly worse than the logistic regression model, it only achives an accuracy of `r knn_accuracy`, the lowest one of all four models.

## Regression tree model

Regression trees operate by predicting an outcome variable by partitioning the predictor space. However, this partioning bears the risk of overtraining. To avoid this situation, my algorithm sets a minimum for how much the residual sum of squares must improve for another partition to be added. This parameter is referred to as the complexity Parameter.

```{r rpart_model, message = FALSE, warning = FALSE}
# compute fit of regression tree algorithm
set.seed(20, sample.kind="Rounding")
rpart_fit <- train(disease ~ ., data = train_set, method = "rpart", 
                   tuneGrid = data.frame(cp = seq(0, 0.05, len = 25)))

# calculate predicted presence of heart disease (with rpart)
rpart_predicted_num <- predict(rpart_fit, test_set)

# use regression tree prediction to compute accuracy on the test set
rpart_accuracy <- accuracy(rpart_predicted_num, test_set$disease)
```

```{r rpart_table, echo = FALSE, message = FALSE}
accuracy_results <- bind_rows(accuracy_results, data_frame(method = "Regression Tree", 
                                                           accuracy = rpart_accuracy))
```

```{r plot_rpart, echo = FALSE}
# plot rpart
ggplot(rpart_fit)

# calculate optimal cp
options(digits = 5)
cp_opt <- rpart_fit$bestTune

# plot regression tree
tree <- rpart(disease ~ ., data = train_set, cp = cp_opt)
rpart.plot(tree)
```

\newpage

The main advantage of regression trees is that they are highly interpretable and easy to visualize. They can model human decision processes and do not require use of dummy predictors for categorical variables.

From the graph we can see that the value of the complexity paramter that optimizes the model is `r cp_opt`. The decision tree illustrates how the algorithm predicts the presence or absence of a heart disease based on available variables. In terms of accuracy, regression trees are rarely the best performing method. The regression tree yields an accuracy of `r rpart_accuracy` which is an improvement compared to the k-nearest neighbor model but still significantly worse than the logistic regression.

Regression trees may not be the best performing method since they are not very flexible, and they are quite susceptible to changes in the training data.

## Random forest model

In a last step, I ran a random forest model. Random forests are a very popular machine learning approach that addresses the shortcomings of regression trees. The goal is to improve prediction performance and reduce instability by averaging multiple regression trees (a forest of trees constructed with randomness). Thereby, $mtry$, the number of variables randomly sampled as candidates at each split, is optimized.

```{r rf_model, message = FALSE, warning = FALSE}
# compute fit of random forest algorithm
set.seed(20, sample.kind="Rounding")
rf_fit <- train(disease ~ ., data = train_set, method = "rf", 
                tuneGrid = data.frame(mtry = seq(50, 200, 10)))

# calculate predicted presence of heart disease (with rf)
rf_predicted_num <- predict(rf_fit, test_set)

# use random forest prediction to compute accuracy on the test set
rf_accuracy <- accuracy(rf_predicted_num, test_set$disease)
```

```{r rf_table, echo = FALSE, message = FALSE}
accuracy_results <- bind_rows(accuracy_results, data_frame(method = "Random Forest", 
                                                           accuracy = rf_accuracy))
```

```{r plot_rf, echo = FALSE}
# plot rf
ggplot(rf_fit, highlight = TRUE)

# calculate optimal mtry
mtry <- rf_fit$bestTune
```

From the graph we can see that the value of $mtry$ that optimizes the model is `r mtry`, thus a random sample of `r mtry` at each split optimizes this model. Thereby, it yields an accuracy of `r rf_accuracy`, a clear improvement to the regression tree model and the second highest of the four models. One small disadvantage of random forests is that interpretability is lost.

# Conclusion

```{r output, echo = FALSE, results = 'asis'}
kable(accuracy_results)
```

By testing four different models on the Health Disease dataset, I was able to achieve an accuracy of `r glm_accuracy` with a logistic regression model. The model outperformed the k-nearest neighbor, the regression tree and the random forest model, even though it is the simplest one. This brings me back to one of the key learnings of the course: If you can't beat it with a more complex approach, you probably simply want to stick to regression.

In the future, I aim to explore further machine learning algorithms that outperform the accuracy of the logistic regression model. I am more than happy about my achievements in the Professional Certificate in Data Science course and would strongly recommend it to anyone interested in data science and R.
